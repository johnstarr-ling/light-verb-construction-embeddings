# Give or Take a Few Representations

This repository is home base for the "Give or take a few representations", one of 5 final projects for the FA '22 iteration of _Computational Linguistics II_ (LING 4435) at Cornell University; a rough outline of the topics covered in this course can be found [here](https://vansky.github.io/courses/2020-cl2.html). This project is in collaboration with [Jacob Matthews](https://github.com/jam963) (second author) and [Dr. Marten van Schijndel](https://vansky.github.io/) (course instructor, advisor).

The main goal of this project is to examine how large language models represent light-verb constructions (LVCs). More information about this project -- both in this README file and elsewhere in this repository -- will be updated over the following few weeks. 

Some key notes:

- We collect embedding representations of the {full phrasal verb, the verb only, and the non-verbs only} from [BERT](https://huggingface.co/bert-base-cased) (default in `miniconsbatched.py`), [GPT2](https://huggingface.co/gpt2) , and [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta). Each set of representations for each model has dimensions `(3, 1224, 768)`, with 3 representing the number of layers we collected from (6, 9, 12 (aka last layer)), 1224 representing the number of sentences in the corpus, and 768 representing the dimensionality of each embedding.  All of the embeddings can be found in the `representations` folder in the main repository and are stored as numpy binary files -- you can load them in with `np.load`. To get these embedding representations yourself, run the `get_representations.ipynb` notebook. You'll need to install [https://pypi.org/project/minicons/](https://pypi.org/project/minicons/), as reflected in  `requirements.txt`.

- The current dataset for this project is a Frankensteinien amalgamation of the dataset constructed by Yuancheng Tu and Dan Roth for their 2012 paper ["Sorting Out the Most Confusing English Phrasal Verbs"](https://cogcomp.seas.upenn.edu/page/publication_view/689). Major thanks to them for building easy-to-use datasets!