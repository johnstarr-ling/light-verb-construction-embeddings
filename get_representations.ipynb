{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Representations for Phrasal VERBS\n",
    "In this notebook, I generate all the necessary embeddings for each element of the phrasal verb:\n",
    "\n",
    "1. the whole phrasal verb\n",
    "2. the verb only\n",
    "3. all non-verb elements in the phrasal verb\n",
    "\n",
    "This notebook ~28 minutes to run (currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from miniconsbatched import generate_representations\n",
    "\n",
    "from minicons import cwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('data/pvc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating verbs and non-verb elements\n",
    "data['verb_string_only'] = data['verbs_fixed'].apply(lambda x: eval(x)[0])\n",
    "data['non_verbs_only'] = data['verbs_fixed'].apply(lambda x: ' '.join(eval(x)[1:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Representations for Phrasal Verbs\n",
    "In this section, I get the BERT, GPT2, and RoBERTa representations for all of the phrasal verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running bert-base-cased for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT Reps\n",
    "vectors_bert, pairs_bert = generate_representations(data['verb_string'], data['sent_string'], layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BERT Reps\n",
    "with open('bert_vectors_full.np', 'wb') as f:\n",
    "    np.save(f, vectors_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running gpt2 for layer [0, 3, 6, 9, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate GPT2 Reps\n",
    "vectors_gpt2, pairs_gpt2 = generate_representations(data['verb_string'], data['sent_string'], model='gpt2', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving GPT2 Reps\n",
    "with open('gpt_vectors_full.np', 'wb') as gpt:\n",
    "    np.save(gpt, vectors_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running roberta-base for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate roberta Reps\n",
    "vectors_roberta, pairs_roberta = generate_representations(data['verb_string'], data['sent_string'], model='roberta-base', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RoBERTa Reps\n",
    "with open('roberta_vectors_full.np', 'wb') as rob:\n",
    "    np.save(rob, vectors_roberta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Representations for Verbs Only\n",
    "In this section, I get the BERT, GPT2, and RoBERTa representations for _only_ the verb in each phrasal verb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running bert-base-cased for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT Reps\n",
    "vectors_bert_verb, pairs_bert_verb = generate_representations(data['verb_string_only'], data['sent_string'], layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BERT Reps\n",
    "with open('bert_vectors_verb.np', 'wb') as bert_verb:\n",
    "    np.save(bert_verb, vectors_bert_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running gpt2 for layer [0, 3, 6, 9, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate GPT2 Reps\n",
    "vectors_gpt2_verb, pairs_gpt2_verb = generate_representations(data['verb_string_only'], data['sent_string'], model='gpt2', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving GPT2 Reps\n",
    "with open('gpt_vectors_verb.np', 'wb') as gpt_verb:\n",
    "    np.save(gpt_verb, vectors_gpt2_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running roberta-base for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate RoBERTa Reps\n",
    "vectors_roberta_verb, pairs_roberta_verb = generate_representations(data['verb_string_only'], data['sent_string'], model='roberta-base', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RoBERTa Reps\n",
    "with open('roberta_vectors_verb.np', 'wb') as rob_verb:\n",
    "    np.save(rob_verb, vectors_roberta_verb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Representations for Non-Verbs Only\n",
    "In this section, I get the BERT, GPT2, and RoBERTa representations for everything _except_ the verb in each phrasal verb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running bert-base-cased for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT Reps\n",
    "vectors_bert_nonverb, pairs_bert_nonverb = generate_representations(data['non_verbs_only'], data['sent_string'], layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BERT Reps\n",
    "with open('bert_vectors_nonverb.np', 'wb') as bert_nonverb:\n",
    "    np.save(bert_nonverb, vectors_bert_nonverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running gpt2 for layer [0, 3, 6, 9, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate GPT2 Reps\n",
    "vectors_gpt2_nonverb, pairs_gpt2_nonverb = generate_representations(data['non_verbs_only'], data['sent_string'], model='gpt2', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving GPT2 Reps\n",
    "with open('gpt_vectors_nonverb.np', 'wb') as gpt_nonverb:\n",
    "    np.save(gpt_nonverb, vectors_gpt2_nonverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Running roberta-base for layer [0, 3, 6, 9, 12] !\n",
      "Run complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate RoBERTa Reps\n",
    "vectors_roberta_nonverb, pairs_roberta_nonverb = generate_representations(data['non_verbs_only'], data['sent_string'], model='roberta-base', layer=[0,3,6,9,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RoBERTa Reps\n",
    "with open('roberta_vectors_nonverb.np', 'wb') as rob_nonverb:\n",
    "    np.save(rob_nonverb, vectors_roberta_nonverb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads in some of the representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoBERTa Reps\n",
    "with open('roberta_vectors_nonverb.np', 'rb') as test_rob:\n",
    "    test_rob_loaded = np.load(test_rob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Function\n",
    "\n",
    "In the following code blocks, I construct a master function that gets embeddings (full phrasal verb, verb only, nonverb only) for all 12 layers of BERT, GPT2, RoBERTa, XLNet, DistilGPT, and DistilBERT. \n",
    "\n",
    "On my laptop (Dell XPS 13 from 2020; no GPUs), the code takes this long to run: 47 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['bert-base-cased', 'roberta-base', 'gpt2', 'xlnet-base-cased', 'distilbert-base-cased', 'distilgpt2']\n",
    "embedding_types = ['full_verb', 'verb_only', 'nonverb_only']\n",
    "verb_strings = np.array((data['verb_string'], data['verb_string_only'], data['non_verbs_only']))\n",
    "sent_strings = data['sent_string']\n",
    "layers = [i for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_representations(model, embedding_type, verb_strings, sent_strings, layer):\n",
    "    vectors, pairs = generate_representations(verb_strings, sent_strings, model=model, layer=layer)\n",
    "\n",
    "    with open(f'{model}_{embedding_type}_vectors.np', 'wb') as out:\n",
    "        np.save(out, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation_pipeline(models=models, embedding_types=embedding_types, verb_strings=verb_strings, sent_strings=sent_strings, layers=layers):\n",
    "    for model in models:\n",
    "        input_layers = layers\n",
    "        if model == 'distilbert-base-cased' or model == 'distilgpt2':\n",
    "            input_layers = input_layers[:7]\n",
    "        print(f'################# WORKING ON {model} #################')\n",
    "        for i in range(len(embedding_types)):\n",
    "            print(f'### BUILDING {embedding_types[i]} ###')\n",
    "            build_and_save_representations(model, embedding_types[i], verb_strings[i],\n",
    "                                            sent_strings, input_layers)\n",
    "        print(f'################# {model} COMPLETE #################')\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# WORKING ON bert-base-cased #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running bert-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running bert-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running bert-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "################# bert-base-cased COMPLETE #################\n",
      "\n",
      "\n",
      "\n",
      "################# WORKING ON roberta-base #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running roberta-base for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running roberta-base for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running roberta-base for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "################# roberta-base COMPLETE #################\n",
      "\n",
      "\n",
      "\n",
      "################# WORKING ON gpt2 #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running gpt2 for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 681kB/s]\n",
      "c:\\Users\\johns\\Anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\johns\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 6.39MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 4.60MB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 7.67MB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [01:00<00:00, 9.06MB/s] \n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running gpt2 for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running gpt2 for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "################# gpt2 COMPLETE #################\n",
      "\n",
      "\n",
      "\n",
      "################# WORKING ON xlnet-base-cased #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running xlnet-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running xlnet-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running xlnet-base-cased for layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] !\n",
      "Run complete.\n",
      "\n",
      "################# xlnet-base-cased COMPLETE #################\n",
      "\n",
      "\n",
      "\n",
      "################# WORKING ON distilbert-base-cased #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running distilbert-base-cased for layer [0, 1, 2, 3, 4, 5, 6] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 8.42kB/s]\n",
      "Downloading: 100%|██████████| 411/411 [00:00<00:00, 275kB/s]\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 3.07MB/s]\n",
      "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 3.88MB/s]\n",
      "Downloading: 100%|██████████| 263M/263M [00:31<00:00, 8.42MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running distilbert-base-cased for layer [0, 1, 2, 3, 4, 5, 6] !\n",
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running distilbert-base-cased for layer [0, 1, 2, 3, 4, 5, 6] !\n",
      "Run complete.\n",
      "\n",
      "################# distilbert-base-cased COMPLETE #################\n",
      "\n",
      "\n",
      "\n",
      "################# WORKING ON distilgpt2 #################\n",
      "### BUILDING full_verb ###\n",
      "########################################\n",
      "Running distilgpt2 for layer [0, 1, 2, 3, 4, 5, 6] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "### BUILDING verb_only ###\n",
      "########################################\n",
      "Running distilgpt2 for layer [0, 1, 2, 3, 4, 5, 6] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "### BUILDING nonverb_only ###\n",
      "########################################\n",
      "Running distilgpt2 for layer [0, 1, 2, 3, 4, 5, 6] !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run complete.\n",
      "\n",
      "################# distilgpt2 COMPLETE #################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The whole shibang!\n",
    "representation_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99e36c4e7668e780a07345726bda8c16f8801d43d9a537c65be6dd0ae0350df0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
