{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Embeddings\n",
    "\n",
    "Hi!\n",
    "\n",
    "In this notebook, I create multiple embedding representations for the phrasal verb data found [here](https://github.com/johnstarr-ling/light-verb-construction-embeddings/tree/main/data).\n",
    "\n",
    "The kinds of embeddings that I currently use are:\n",
    "1. pre-trained Word2Vec word embeddings (300d, trained on Google News Corpus)\n",
    "2. pre-trained Word2Vec word embeddings (300d, trained on Google News Corpus), with phrasal verb as one compositional embedding (mean pooling)\n",
    "3. pre-trained GLoVe word embeddings (300d, trained on Wikipedia 2014 + Gigaword 5 corpora)\n",
    "4. pre-trained GLoVe word embeddings (300d, trained on Wikipedia 2014 + Gigaword 5 corpora), with phrasal verb as one compositional embedding (mean pooling)\n",
    "5. [InferSent](https://github.com/facebookresearch/InferSent) sentence embeddings\n",
    "\n",
    "Embedding representations that I expect to use in the future include:\n",
    "1. BERT\n",
    "\n",
    "__NOTE ON RUNNING THIS NOTEBOOK:__ This notebook requires the following files to be in the same directory for a successful run:\n",
    "1. [models.py](https://github.com/facebookresearch/InferSent/blob/main/models.py) file from InferSent\n",
    "2. [a pretrained GLoVe embedding .txt file](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load in our phrasal verb data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/pvc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvc_lemmas</th>\n",
       "      <th>file_path</th>\n",
       "      <th>row</th>\n",
       "      <th>is_phrasal</th>\n",
       "      <th>annotator_agreement_percentage</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['take', 'on']</td>\n",
       "      <td>B/BN/BNN.xml</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>['12', '13']</td>\n",
       "      <td>['At', 'about', 'the', 'same', 'time', 'the', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['give', 'in']</td>\n",
       "      <td>B/B1/B1E.xml</td>\n",
       "      <td>670</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>['15', '16']</td>\n",
       "      <td>['Production', 'is', 'centred', 'in', 'the', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['take', 'after']</td>\n",
       "      <td>K/K3/K3E.xml</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>['21', '22']</td>\n",
       "      <td>['By', 'Echo', 'reporter', 'CORONATION', 'Stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['get', 'out']</td>\n",
       "      <td>C/CK/CK9.xml</td>\n",
       "      <td>1654</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>['19', '20']</td>\n",
       "      <td>['Mrs', 'Aggie', ',', 'I', 'do', 'want', 'to',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['get', 'through']</td>\n",
       "      <td>G/G2/G2E.xml</td>\n",
       "      <td>2734</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>['9', '10']</td>\n",
       "      <td>['He', 'was', 'charged', 'for', 'a', 'call', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pvc_lemmas     file_path   row  is_phrasal  \\\n",
       "0      ['take', 'on']  B/BN/BNN.xml   291        True   \n",
       "1      ['give', 'in']  B/B1/B1E.xml   670       False   \n",
       "2   ['take', 'after']  K/K3/K3E.xml    56       False   \n",
       "3      ['get', 'out']  C/CK/CK9.xml  1654        True   \n",
       "4  ['get', 'through']  G/G2/G2E.xml  2734        True   \n",
       "\n",
       "   annotator_agreement_percentage      verb_idx  \\\n",
       "0                          1.0000  ['12', '13']   \n",
       "1                          0.7051  ['15', '16']   \n",
       "2                          0.6733  ['21', '22']   \n",
       "3                          1.0000  ['19', '20']   \n",
       "4                          1.0000   ['9', '10']   \n",
       "\n",
       "                                               sents  \n",
       "0  ['At', 'about', 'the', 'same', 'time', 'the', ...  \n",
       "1  ['Production', 'is', 'centred', 'in', 'the', '...  \n",
       "2  ['By', 'Echo', 'reporter', 'CORONATION', 'Stre...  \n",
       "3  ['Mrs', 'Aggie', ',', 'I', 'do', 'want', 'to',...  \n",
       "4  ['He', 'was', 'charged', 'for', 'a', 'call', '...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all our data are in the right form\n",
    "data['pvc_lemmas'] = data['pvc_lemmas'].apply(eval)\n",
    "data['row'] = data['row'].apply(int)\n",
    "data['annotator_agreement_percentage'] = data['annotator_agreement_percentage'].apply(float)\n",
    "data['verb_idx'] = data['verb_idx'].apply(eval)\n",
    "data['sents'] = data['sents'].apply(eval)\n",
    "data['pvc_strings'] = data['pvc_lemmas'].apply(lambda x: ' '.join(x))\n",
    "data['sent_strings'] = data['sents'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InferSent\n",
    "\n",
    "Most of the following code is taken from [here](https://github.com/facebookresearch/InferSent/blob/main/demo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from model import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'glove.6B.300d.txt' if model_version == 1 else 'fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some test sentences!\n",
    "test_lvcs = ['I gave John a bath .', 'I gave John a book .', 'I gave John a chance .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 12/24 (50.0%)\n",
      "Speed : 124.8 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 3\n"
     ]
    }
   ],
   "source": [
    "test_embeds = model.encode(test_lvcs, bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(test_lvcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86921847"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(model.encode(['I gave John a bath.'])[0], model.encode(['I gave John a book.'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 2616/5142 (50.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\Documents\\grad_school\\research\\light-verb-construction-embeddings\\model.py:207: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 804.0 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 1263\n"
     ]
    }
   ],
   "source": [
    "# Phrasal verb embedding\n",
    "pv_embeddings = model.encode(data['pvc_strings'], bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 30795/36617 (84.1%)\n",
      "Speed : 66.4 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 1263\n"
     ]
    }
   ],
   "source": [
    "# Whole sentence embedding\n",
    "sent_embeddings = model.encode(data['sent_strings'], bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding these to the DataFrame\n",
    "pv_infer_list = list(pv_embeddings)\n",
    "sent_infer_list = list(sent_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pv_infer_embeds'] = pv_infer_list\n",
    "data['sent_infer_embeds'] = sent_infer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvc_lemmas</th>\n",
       "      <th>file_path</th>\n",
       "      <th>row</th>\n",
       "      <th>is_phrasal</th>\n",
       "      <th>annotator_agreement_percentage</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>sents</th>\n",
       "      <th>pvc_strings</th>\n",
       "      <th>sent_strings</th>\n",
       "      <th>pv_infer_embeds</th>\n",
       "      <th>sent_infer_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[take, on]</td>\n",
       "      <td>B/BN/BNN.xml</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>[At, about, the, same, time, the, aliens, depa...</td>\n",
       "      <td>take on</td>\n",
       "      <td>At about the same time the aliens department o...</td>\n",
       "      <td>[0.04849784, 0.082029976, 0.010337902, 0.00278...</td>\n",
       "      <td>[0.12564819, 0.06340436, 0.055802934, 0.096010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[give, in]</td>\n",
       "      <td>B/B1/B1E.xml</td>\n",
       "      <td>670</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>[Production, is, centred, in, the, Pacific, no...</td>\n",
       "      <td>give in</td>\n",
       "      <td>Production is centred in the Pacific northwest...</td>\n",
       "      <td>[0.06049606, 0.066955656, -0.0019042839, -0.05...</td>\n",
       "      <td>[0.07641017, 0.13320042, 0.008155916, 0.096234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[take, after]</td>\n",
       "      <td>K/K3/K3E.xml</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[By, Echo, reporter, CORONATION, Street, actre...</td>\n",
       "      <td>take after</td>\n",
       "      <td>By Echo reporter CORONATION Street actress Lyn...</td>\n",
       "      <td>[0.04559154, 0.013943457, 0.013154965, -0.0398...</td>\n",
       "      <td>[0.116348945, 0.07574034, 0.013408521, 0.07490...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[get, out]</td>\n",
       "      <td>C/CK/CK9.xml</td>\n",
       "      <td>1654</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[19, 20]</td>\n",
       "      <td>[Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...</td>\n",
       "      <td>get out</td>\n",
       "      <td>Mrs Aggie , I do want to go to a school where ...</td>\n",
       "      <td>[0.04216131, -0.040760946, -0.071714684, -0.00...</td>\n",
       "      <td>[0.08019499, 0.06795283, 0.053973824, 0.092289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[get, through]</td>\n",
       "      <td>G/G2/G2E.xml</td>\n",
       "      <td>2734</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[He, was, charged, for, a, call, that, never, ...</td>\n",
       "      <td>get through</td>\n",
       "      <td>He was charged for a call that never got throu...</td>\n",
       "      <td>[0.07250941, -0.0235534, -0.04305069, 0.039528...</td>\n",
       "      <td>[0.07009956, 0.052870482, 0.08822129, 0.059288...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pvc_lemmas     file_path   row  is_phrasal  \\\n",
       "0      [take, on]  B/BN/BNN.xml   291        True   \n",
       "1      [give, in]  B/B1/B1E.xml   670       False   \n",
       "2   [take, after]  K/K3/K3E.xml    56       False   \n",
       "3      [get, out]  C/CK/CK9.xml  1654        True   \n",
       "4  [get, through]  G/G2/G2E.xml  2734        True   \n",
       "\n",
       "   annotator_agreement_percentage  verb_idx  \\\n",
       "0                          1.0000  [12, 13]   \n",
       "1                          0.7051  [15, 16]   \n",
       "2                          0.6733  [21, 22]   \n",
       "3                          1.0000  [19, 20]   \n",
       "4                          1.0000   [9, 10]   \n",
       "\n",
       "                                               sents  pvc_strings  \\\n",
       "0  [At, about, the, same, time, the, aliens, depa...      take on   \n",
       "1  [Production, is, centred, in, the, Pacific, no...      give in   \n",
       "2  [By, Echo, reporter, CORONATION, Street, actre...   take after   \n",
       "3  [Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...      get out   \n",
       "4  [He, was, charged, for, a, call, that, never, ...  get through   \n",
       "\n",
       "                                        sent_strings  \\\n",
       "0  At about the same time the aliens department o...   \n",
       "1  Production is centred in the Pacific northwest...   \n",
       "2  By Echo reporter CORONATION Street actress Lyn...   \n",
       "3  Mrs Aggie , I do want to go to a school where ...   \n",
       "4  He was charged for a call that never got throu...   \n",
       "\n",
       "                                     pv_infer_embeds  \\\n",
       "0  [0.04849784, 0.082029976, 0.010337902, 0.00278...   \n",
       "1  [0.06049606, 0.066955656, -0.0019042839, -0.05...   \n",
       "2  [0.04559154, 0.013943457, 0.013154965, -0.0398...   \n",
       "3  [0.04216131, -0.040760946, -0.071714684, -0.00...   \n",
       "4  [0.07250941, -0.0235534, -0.04305069, 0.039528...   \n",
       "\n",
       "                                   sent_infer_embeds  \n",
       "0  [0.12564819, 0.06340436, 0.055802934, 0.096010...  \n",
       "1  [0.07641017, 0.13320042, 0.008155916, 0.096234...  \n",
       "2  [0.116348945, 0.07574034, 0.013408521, 0.07490...  \n",
       "3  [0.08019499, 0.06795283, 0.053973824, 0.092289...  \n",
       "4  [0.07009956, 0.052870482, 0.08822129, 0.059288...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an <UNK> that is the mean of all vectors in the space\n",
    "w2v['<UNK>'] = np.mean([w2v[x] for x in w2v.key_to_index.keys()], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the vectors to the list\n",
    "def get_w2v_list(word_list, vectors):\n",
    "    vector_list = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            vector_list.append(vectors[word])\n",
    "        except:\n",
    "            vector_list.append(vectors['<UNK>'])\n",
    "    return vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding representations\n",
    "data['pv_w2v_embed'] = data['pvc_lemmas'].apply(lambda x: get_w2v_list(x, w2v))\n",
    "data['sent_w2v_embed'] = data['sents'].apply(lambda x: get_w2v_list(x, w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvc_lemmas</th>\n",
       "      <th>file_path</th>\n",
       "      <th>row</th>\n",
       "      <th>is_phrasal</th>\n",
       "      <th>annotator_agreement_percentage</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>sents</th>\n",
       "      <th>pvc_strings</th>\n",
       "      <th>sent_strings</th>\n",
       "      <th>pv_infer_embeds</th>\n",
       "      <th>sent_infer_embeds</th>\n",
       "      <th>pv_w2v_embed</th>\n",
       "      <th>sent_w2v_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[take, on]</td>\n",
       "      <td>B/BN/BNN.xml</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>[At, about, the, same, time, the, aliens, depa...</td>\n",
       "      <td>take on</td>\n",
       "      <td>At about the same time the aliens department o...</td>\n",
       "      <td>[0.04849784, 0.082029976, 0.010337902, 0.00278...</td>\n",
       "      <td>[0.12564819, 0.06340436, 0.055802934, 0.096010...</td>\n",
       "      <td>[[-0.05102539, 0.0041503906, 0.024902344, -0.0...</td>\n",
       "      <td>[[-0.088378906, -0.011962891, 0.21484375, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[give, in]</td>\n",
       "      <td>B/B1/B1E.xml</td>\n",
       "      <td>670</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>[Production, is, centred, in, the, Pacific, no...</td>\n",
       "      <td>give in</td>\n",
       "      <td>Production is centred in the Pacific northwest...</td>\n",
       "      <td>[0.06049606, 0.066955656, -0.0019042839, -0.05...</td>\n",
       "      <td>[0.07641017, 0.13320042, 0.008155916, 0.096234...</td>\n",
       "      <td>[[0.06201172, -0.122558594, 0.016845703, 0.086...</td>\n",
       "      <td>[[-0.027954102, -0.19042969, -0.02746582, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[take, after]</td>\n",
       "      <td>K/K3/K3E.xml</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[By, Echo, reporter, CORONATION, Street, actre...</td>\n",
       "      <td>take after</td>\n",
       "      <td>By Echo reporter CORONATION Street actress Lyn...</td>\n",
       "      <td>[0.04559154, 0.013943457, 0.013154965, -0.0398...</td>\n",
       "      <td>[0.116348945, 0.07574034, 0.013408521, 0.07490...</td>\n",
       "      <td>[[-0.05102539, 0.0041503906, 0.024902344, -0.0...</td>\n",
       "      <td>[[-0.047851562, -0.29492188, 0.375, 0.359375, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[get, out]</td>\n",
       "      <td>C/CK/CK9.xml</td>\n",
       "      <td>1654</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[19, 20]</td>\n",
       "      <td>[Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...</td>\n",
       "      <td>get out</td>\n",
       "      <td>Mrs Aggie , I do want to go to a school where ...</td>\n",
       "      <td>[0.04216131, -0.040760946, -0.071714684, -0.00...</td>\n",
       "      <td>[0.08019499, 0.06795283, 0.053973824, 0.092289...</td>\n",
       "      <td>[[0.033203125, -0.08984375, -0.29492188, 0.115...</td>\n",
       "      <td>[[0.23242188, -0.1875, -0.28125, -0.06542969, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[get, through]</td>\n",
       "      <td>G/G2/G2E.xml</td>\n",
       "      <td>2734</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[He, was, charged, for, a, call, that, never, ...</td>\n",
       "      <td>get through</td>\n",
       "      <td>He was charged for a call that never got throu...</td>\n",
       "      <td>[0.07250941, -0.0235534, -0.04305069, 0.039528...</td>\n",
       "      <td>[0.07009956, 0.052870482, 0.08822129, 0.059288...</td>\n",
       "      <td>[[0.033203125, -0.08984375, -0.29492188, 0.115...</td>\n",
       "      <td>[[-0.038085938, 0.34570312, 0.103027344, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pvc_lemmas     file_path   row  is_phrasal  \\\n",
       "0      [take, on]  B/BN/BNN.xml   291        True   \n",
       "1      [give, in]  B/B1/B1E.xml   670       False   \n",
       "2   [take, after]  K/K3/K3E.xml    56       False   \n",
       "3      [get, out]  C/CK/CK9.xml  1654        True   \n",
       "4  [get, through]  G/G2/G2E.xml  2734        True   \n",
       "\n",
       "   annotator_agreement_percentage  verb_idx  \\\n",
       "0                          1.0000  [12, 13]   \n",
       "1                          0.7051  [15, 16]   \n",
       "2                          0.6733  [21, 22]   \n",
       "3                          1.0000  [19, 20]   \n",
       "4                          1.0000   [9, 10]   \n",
       "\n",
       "                                               sents  pvc_strings  \\\n",
       "0  [At, about, the, same, time, the, aliens, depa...      take on   \n",
       "1  [Production, is, centred, in, the, Pacific, no...      give in   \n",
       "2  [By, Echo, reporter, CORONATION, Street, actre...   take after   \n",
       "3  [Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...      get out   \n",
       "4  [He, was, charged, for, a, call, that, never, ...  get through   \n",
       "\n",
       "                                        sent_strings  \\\n",
       "0  At about the same time the aliens department o...   \n",
       "1  Production is centred in the Pacific northwest...   \n",
       "2  By Echo reporter CORONATION Street actress Lyn...   \n",
       "3  Mrs Aggie , I do want to go to a school where ...   \n",
       "4  He was charged for a call that never got throu...   \n",
       "\n",
       "                                     pv_infer_embeds  \\\n",
       "0  [0.04849784, 0.082029976, 0.010337902, 0.00278...   \n",
       "1  [0.06049606, 0.066955656, -0.0019042839, -0.05...   \n",
       "2  [0.04559154, 0.013943457, 0.013154965, -0.0398...   \n",
       "3  [0.04216131, -0.040760946, -0.071714684, -0.00...   \n",
       "4  [0.07250941, -0.0235534, -0.04305069, 0.039528...   \n",
       "\n",
       "                                   sent_infer_embeds  \\\n",
       "0  [0.12564819, 0.06340436, 0.055802934, 0.096010...   \n",
       "1  [0.07641017, 0.13320042, 0.008155916, 0.096234...   \n",
       "2  [0.116348945, 0.07574034, 0.013408521, 0.07490...   \n",
       "3  [0.08019499, 0.06795283, 0.053973824, 0.092289...   \n",
       "4  [0.07009956, 0.052870482, 0.08822129, 0.059288...   \n",
       "\n",
       "                                        pv_w2v_embed  \\\n",
       "0  [[-0.05102539, 0.0041503906, 0.024902344, -0.0...   \n",
       "1  [[0.06201172, -0.122558594, 0.016845703, 0.086...   \n",
       "2  [[-0.05102539, 0.0041503906, 0.024902344, -0.0...   \n",
       "3  [[0.033203125, -0.08984375, -0.29492188, 0.115...   \n",
       "4  [[0.033203125, -0.08984375, -0.29492188, 0.115...   \n",
       "\n",
       "                                      sent_w2v_embed  \n",
       "0  [[-0.088378906, -0.011962891, 0.21484375, 0.05...  \n",
       "1  [[-0.027954102, -0.19042969, -0.02746582, -0.1...  \n",
       "2  [[-0.047851562, -0.29492188, 0.375, 0.359375, ...  \n",
       "3  [[0.23242188, -0.1875, -0.28125, -0.06542969, ...  \n",
       "4  [[-0.038085938, 0.34570312, 0.103027344, -0.03...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLoVe\n",
    "\n",
    "__NOTE:__ Uncomment the following final line in the following code block if you have _not_ created a w2v filetype from the GLoVe embeddings already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_filename = 'glove.6B.300d.txt'\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "# glove2word2vec(glove_filename, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take a while to run :( \n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an <UNK> representation that consists of the mean of the embedding space\n",
    "glove['<UNK>'] = np.mean([glove[x] for x in glove.key_to_index.keys()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove(token_list, model):\n",
    "    vector_list = []\n",
    "    for word in token_list:\n",
    "        try:\n",
    "            vector_list.append(model[word])\n",
    "        except:\n",
    "            vector_list.append(model['<UNK>'])\n",
    "    return vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving vector representations for everything!\n",
    "data['pv_glove_embed'] = data['pvc_lemmas'].apply(lambda x: get_glove(x, glove))\n",
    "data['sent_glove_embed'] = data['pvc_lemmas'].apply(lambda x: get_glove(x, glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvc_lemmas</th>\n",
       "      <th>file_path</th>\n",
       "      <th>row</th>\n",
       "      <th>is_phrasal</th>\n",
       "      <th>annotator_agreement_percentage</th>\n",
       "      <th>verb_idx</th>\n",
       "      <th>sents</th>\n",
       "      <th>pvc_strings</th>\n",
       "      <th>sent_strings</th>\n",
       "      <th>pv_infer_embeds</th>\n",
       "      <th>sent_infer_embeds</th>\n",
       "      <th>pv_w2v_embed</th>\n",
       "      <th>sent_w2v_embed</th>\n",
       "      <th>pv_glove_embed</th>\n",
       "      <th>sent_glove_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[take, on]</td>\n",
       "      <td>B/BN/BNN.xml</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>[At, about, the, same, time, the, aliens, depa...</td>\n",
       "      <td>take on</td>\n",
       "      <td>At about the same time the aliens department o...</td>\n",
       "      <td>[0.04849784, 0.082029976, 0.010337902, 0.00278...</td>\n",
       "      <td>[0.12564819, 0.06340436, 0.055802934, 0.096010...</td>\n",
       "      <td>[[-0.05102539, 0.0041503906, 0.024902344, -0.0...</td>\n",
       "      <td>[[-0.088378906, -0.011962891, 0.21484375, 0.05...</td>\n",
       "      <td>[[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...</td>\n",
       "      <td>[[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[give, in]</td>\n",
       "      <td>B/B1/B1E.xml</td>\n",
       "      <td>670</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>[Production, is, centred, in, the, Pacific, no...</td>\n",
       "      <td>give in</td>\n",
       "      <td>Production is centred in the Pacific northwest...</td>\n",
       "      <td>[0.06049606, 0.066955656, -0.0019042839, -0.05...</td>\n",
       "      <td>[0.07641017, 0.13320042, 0.008155916, 0.096234...</td>\n",
       "      <td>[[0.06201172, -0.122558594, 0.016845703, 0.086...</td>\n",
       "      <td>[[-0.027954102, -0.19042969, -0.02746582, -0.1...</td>\n",
       "      <td>[[0.1088, -0.21724, -0.55772, -0.15096, 0.0473...</td>\n",
       "      <td>[[0.1088, -0.21724, -0.55772, -0.15096, 0.0473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[take, after]</td>\n",
       "      <td>K/K3/K3E.xml</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>[21, 22]</td>\n",
       "      <td>[By, Echo, reporter, CORONATION, Street, actre...</td>\n",
       "      <td>take after</td>\n",
       "      <td>By Echo reporter CORONATION Street actress Lyn...</td>\n",
       "      <td>[0.04559154, 0.013943457, 0.013154965, -0.0398...</td>\n",
       "      <td>[0.116348945, 0.07574034, 0.013408521, 0.07490...</td>\n",
       "      <td>[[-0.05102539, 0.0041503906, 0.024902344, -0.0...</td>\n",
       "      <td>[[-0.047851562, -0.29492188, 0.375, 0.359375, ...</td>\n",
       "      <td>[[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...</td>\n",
       "      <td>[[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[get, out]</td>\n",
       "      <td>C/CK/CK9.xml</td>\n",
       "      <td>1654</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[19, 20]</td>\n",
       "      <td>[Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...</td>\n",
       "      <td>get out</td>\n",
       "      <td>Mrs Aggie , I do want to go to a school where ...</td>\n",
       "      <td>[0.04216131, -0.040760946, -0.071714684, -0.00...</td>\n",
       "      <td>[0.08019499, 0.06795283, 0.053973824, 0.092289...</td>\n",
       "      <td>[[0.033203125, -0.08984375, -0.29492188, 0.115...</td>\n",
       "      <td>[[0.23242188, -0.1875, -0.28125, -0.06542969, ...</td>\n",
       "      <td>[[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...</td>\n",
       "      <td>[[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[get, through]</td>\n",
       "      <td>G/G2/G2E.xml</td>\n",
       "      <td>2734</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[He, was, charged, for, a, call, that, never, ...</td>\n",
       "      <td>get through</td>\n",
       "      <td>He was charged for a call that never got throu...</td>\n",
       "      <td>[0.07250941, -0.0235534, -0.04305069, 0.039528...</td>\n",
       "      <td>[0.07009956, 0.052870482, 0.08822129, 0.059288...</td>\n",
       "      <td>[[0.033203125, -0.08984375, -0.29492188, 0.115...</td>\n",
       "      <td>[[-0.038085938, 0.34570312, 0.103027344, -0.03...</td>\n",
       "      <td>[[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...</td>\n",
       "      <td>[[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pvc_lemmas     file_path   row  is_phrasal  \\\n",
       "0      [take, on]  B/BN/BNN.xml   291        True   \n",
       "1      [give, in]  B/B1/B1E.xml   670       False   \n",
       "2   [take, after]  K/K3/K3E.xml    56       False   \n",
       "3      [get, out]  C/CK/CK9.xml  1654        True   \n",
       "4  [get, through]  G/G2/G2E.xml  2734        True   \n",
       "\n",
       "   annotator_agreement_percentage  verb_idx  \\\n",
       "0                          1.0000  [12, 13]   \n",
       "1                          0.7051  [15, 16]   \n",
       "2                          0.6733  [21, 22]   \n",
       "3                          1.0000  [19, 20]   \n",
       "4                          1.0000   [9, 10]   \n",
       "\n",
       "                                               sents  pvc_strings  \\\n",
       "0  [At, about, the, same, time, the, aliens, depa...      take on   \n",
       "1  [Production, is, centred, in, the, Pacific, no...      give in   \n",
       "2  [By, Echo, reporter, CORONATION, Street, actre...   take after   \n",
       "3  [Mrs, Aggie, ,, I, do, want, to, go, to, a, sc...      get out   \n",
       "4  [He, was, charged, for, a, call, that, never, ...  get through   \n",
       "\n",
       "                                        sent_strings  \\\n",
       "0  At about the same time the aliens department o...   \n",
       "1  Production is centred in the Pacific northwest...   \n",
       "2  By Echo reporter CORONATION Street actress Lyn...   \n",
       "3  Mrs Aggie , I do want to go to a school where ...   \n",
       "4  He was charged for a call that never got throu...   \n",
       "\n",
       "                                     pv_infer_embeds  \\\n",
       "0  [0.04849784, 0.082029976, 0.010337902, 0.00278...   \n",
       "1  [0.06049606, 0.066955656, -0.0019042839, -0.05...   \n",
       "2  [0.04559154, 0.013943457, 0.013154965, -0.0398...   \n",
       "3  [0.04216131, -0.040760946, -0.071714684, -0.00...   \n",
       "4  [0.07250941, -0.0235534, -0.04305069, 0.039528...   \n",
       "\n",
       "                                   sent_infer_embeds  \\\n",
       "0  [0.12564819, 0.06340436, 0.055802934, 0.096010...   \n",
       "1  [0.07641017, 0.13320042, 0.008155916, 0.096234...   \n",
       "2  [0.116348945, 0.07574034, 0.013408521, 0.07490...   \n",
       "3  [0.08019499, 0.06795283, 0.053973824, 0.092289...   \n",
       "4  [0.07009956, 0.052870482, 0.08822129, 0.059288...   \n",
       "\n",
       "                                        pv_w2v_embed  \\\n",
       "0  [[-0.05102539, 0.0041503906, 0.024902344, -0.0...   \n",
       "1  [[0.06201172, -0.122558594, 0.016845703, 0.086...   \n",
       "2  [[-0.05102539, 0.0041503906, 0.024902344, -0.0...   \n",
       "3  [[0.033203125, -0.08984375, -0.29492188, 0.115...   \n",
       "4  [[0.033203125, -0.08984375, -0.29492188, 0.115...   \n",
       "\n",
       "                                      sent_w2v_embed  \\\n",
       "0  [[-0.088378906, -0.011962891, 0.21484375, 0.05...   \n",
       "1  [[-0.027954102, -0.19042969, -0.02746582, -0.1...   \n",
       "2  [[-0.047851562, -0.29492188, 0.375, 0.359375, ...   \n",
       "3  [[0.23242188, -0.1875, -0.28125, -0.06542969, ...   \n",
       "4  [[-0.038085938, 0.34570312, 0.103027344, -0.03...   \n",
       "\n",
       "                                      pv_glove_embed  \\\n",
       "0  [[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...   \n",
       "1  [[0.1088, -0.21724, -0.55772, -0.15096, 0.0473...   \n",
       "2  [[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...   \n",
       "3  [[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...   \n",
       "4  [[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...   \n",
       "\n",
       "                                    sent_glove_embed  \n",
       "0  [[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...  \n",
       "1  [[0.1088, -0.21724, -0.55772, -0.15096, 0.0473...  \n",
       "2  [[-0.015879, 0.11807, -0.12769, -0.16302, -0.0...  \n",
       "3  [[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...  \n",
       "4  [[-0.14124, -0.11836, -0.30782, 0.098416, 0.22...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to data/ folder:\n",
    "data.to_csv('data/pvc_with_embeds.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's it! This is how I constructed the embedding representations from a modified version of the PVC corpus described in [this paper](https://cogcomp.seas.upenn.edu/papers/TuRoth12.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 ('run_jup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3beb3a7e2c76c50ac9a52af5a4e81b8f4ab148094bec6a90da73f5453ca70174"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
